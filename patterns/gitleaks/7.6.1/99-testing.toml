# Testing Patterns
#
# These patterns are the lowest presidence (i.e. 99-) because they could
# collide with other production patterns. Since secret leak uniquness is
# currently being determined by line (combined with some other attrs), these
# collisions were causing things to be missed. Putting them at the end should
# resolve that.
#
# The Structure of This File
#
# This file is broken into multiple sections. Each section starts with # [file:
# and the filename that the patterns in that section will go into once
# production ready.
#
# Tags
#
# All rules in this should have the group:leaktk-testing tag set and no alert:*
# tags set in addition to the other tags called out by the README.
#
# Promoting to Production
#
# The test patterns are deployed to the pattern server just like the other
# patterns. The leaktk-testing group and lack of alert tags put them in a sort
# of "test mode". The general process for making them production ready is:
#
# 1 Deploy the patterns
# 2 Wait 30 days
# 3 Review the scanner results during the monthly tuning
# 4 Tune the patterns
# 5 If there were too many false positives in the last 30 days, repeat 1-5
# 6 Move the test patterns to the file called out by their section
# 7 Remove the group:leatk-testing tag and add the appropriate alert tags
# 8 Repeat
#
# Note About Moving Patterns
#
# Try to keep patterns roughly alphabetically and/or grouped together. Or rather
# don't spread related patterns out. Spreading them out makes it harder to
# notice when changes need to be made in multiple places with related patterns.
#

# [file:98-general.toml]
[[rules]]
  # Find secrets where the file name is the context instead of contents
  # TODO: Remove (File) when prod ready
  description = "(File) General Secret"
  path='''(?i)\.[\w\-]*(secret|token|password)$'''
  # This will probably need to be tuned over time
  regex='''^([^\s]{5,})$'''
  # TODO: replace group:leaktk-testing with alert:repo-owner once tested
  tags = ["group:leaktk-testing", "type:secret", "general", "secret"]

  [rules.allowlist]
    paths = [
      # Test data files are often false positives
      '''(^|\/)testdata\/''',
    ]

    regexes = [
      ## Starts with
      '''^(your|place|put|insert)''',
      ## Ends with
      '''(here|token|value)$''',
      ## Contains
      '''(xxx|example|placeholder|passw(or)?d)''',
    ]

  [[rules.entropies]]
    Min = "3.35"
    Max = "8"
    Group = "1"

[[rules]]
  # This is a copy of General Secret that looks for "token" instead.
  # When this rule is ready, merge it with the regluar General Secret.
  # This intentially just replaces (secret|password) with (token) so that
  # the merge will be (secret|password|token)
  # Note: Token specific ignore patterns will be added to the top of the regexes
  # and noted
  description = "(Token) General Secret"
  regex = '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\']([^\"\s]+?)[\"\']'''
  tags = ["group:leaktk-testing", "key", "general", "secret", "type:secret"]

  [[rules.entropies]]
    Min = "3.35"
    Max = "8"
    Group = "6"

  [rules.allowlist]
    paths = [
      # Test data files are often false positives
      '''(^|\/)testdata\/''',
      # Usually a project not owned by the user that has a lot of FPs for us when
      # folks fork it. But make sure to include the azure-cli aro modules
      '''/azure-(cli.+\/command_modules\/([^a]|a[^r])|sdk-for-python\/|rest-api-specs\/|docs\/)''',
      # Ignore OpenAPI spec files
      '''(^|\/)openapi\.json$''',
      '''(?i)openapi.*github[^\/]*\.json$''',
    ]

    regexes = [
      # BEGIN TOKEN SPECIFIC IGNORE PATTERNS
      # Already covered by the Slack Token rule
      '''xox[baprs]-([0-9a-zA-Z-]{10,48})?''',
      # Already covered by GitHub rules
      '''gh(o|u|p|s|r)_[0-9A-Za-z]{36,}''',
      '''github_pat_\w{82}''',
      # Already covered byt GitLab rules
      '''glpat-[\w\-]{20}''',
      '''glptt-[0-9a-f]{40}''',
      '''(glrt-|GR1348941)[\w\-]{20}''',
      # END TOKEN SPECIFIC IGNORE PATTERNS

      # Things like:
      #   token = "asdfasdfas" # nosec (used by bandit)
      '''#(\s+)?nosec(\s+|$)''',
      #   token = "asdfasdfas" # noqa: E501
      '''#(\s+)?noqa(:[\s\w]+)?$''',
      #   token = "asdfasdfas" //nolint:gosec
      '''\/\/(\s+)?nolint:gosec(\s+|$)''',
      #   token = "_PLACEHOLDER_"
      #   token = "<PLACEHOLDER>"
      #   token = "@@PLACEHOLDER@@"
      #   token = ").append("foo")
      #   token = "%PLACEHOLDER%"
      #   token = "$PLACEHOLDER$"
      #   token = "`PLACEHOLDER`"
      #   token = "[PLACEHOLDER]"
      #   token = "[%PLACEHOLDER%]"
      #   token = "$(PLACEHOLDER..."
      #   token = "\$(PLACEHOLDER..."
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](_.+?_|<.+?>|@@.+?@@|\).+?\(|%.+?%|\$.+?\$|`.+?`|\[.+?\]|\[%.+?%\]|(\\)?\$\(.*)[\"\']''',
      #   token = "ALL_UPPER_LETTERS_OR_UNDERSCORES"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](?-i)[A-Z_]+?[\"\']''',
      #   token = "{PLACEHOLDER}"
      #   token = "%{PLACEHOLDER}"
      #   token = "\%{PLACEHOLDER}"
      #   token = "${PLACEHOLDER}"
      #   token = "\${PLACEHOLDER}"
      #   token = "#{PLACEHOLDER}"
      #   token = "\#{PLACEHOLDER}"
      #   token = "\${PLACEHOLDER}"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](\\)?[\$%#]?\{.+?\}[\"\']''',
      #   token = "Some...placeholder"
      #   token = "Some***placeholder"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'][^\"\']*?(\.\.\.|\*\*\*)[^\"\']*?[\"\']''',
      #   "token="+some_var+"asdfa"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\']\+.+?\+[\"\'].+?[\"\']''',
      #   token = "(optional char)${PLACEHOLDER}(optional text)"
      #   token = "(optional char)#{PLACEHOLDER}(optional text)"
      #   token = "FOO_BAR=($|#){PLACEHOLDER}(optional text)"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\']((?-i)[A-Z_]{6,})?(.)?[\$#]\{.{4,}?\}.*?[\"\']''',
      #   token = "SOME_CONSTANT_PREFIX_${PLACEHOLDER}"
      #   token = "/SOME/path:${PLACEHOLDER}"
      #   token = "/SOME/path:${PLACEHOLDER}${PLACEHOLDER}"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'][a-z\-\_\/\:]{4,}\$\{[a-z\_\.\$\{\}]{4,}?\}[\"\']''',
      #   token = "$SOME_ENV_VARIABLE-optional-text"
      #   token = "\$SOME_ENV_VARIABLE-optional-text"
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](?-i)(\\)?\$[A-Z][0-9A-Z_]{4,}[\w\-]*?[\"\']''',
      # Known full placeholder passwords
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](ask|redhat)[\"\']''',
      # Base64 encoded EXAMPLE in the text
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'][^\"\']*?(RVhBTVBMR|VYQU1QTEU|FWEFNUExF)[^\"\']*?[\"\']''',
      # aws.* is already covered by a different rule
      '''(?i)aws(.{0,15})(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\']([^\"\s]+?)[\"\']''',
      # jq lookups
      '''jq\s+([\w\-\s]+)?.*\.\w*(token)(_|-)?(key)?''',
      # A common false positive for passwords and secrets (e.g. password = "update-your-postgres-pass-here")
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](?-i).+?[a-z]{2,}-[a-z]{2,}-[a-z]{2,}.+?[\"\']''',
      # Various words at the start and end that signify a placeholder
      ## Starts with
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](&lt;|\\u201c|\\u003c|\$)?(\/etc\/|data\/|\/path\/|(\/var)?\/run\/|(0)?12345|abc(d|12)|admin|ansible|auto|bool:|capi-openstack|change|client|confirm|contrase|demo|dict|django-insecure-|example|(ENC\[|RU5DW|VOQ|FTk)|enter_|fake|false|file:|fixme|grub|http(s)?:\/\/|installation_prefix|invalid|libvirt|none|not|placeholder|pass(w)?(o|0)?(r)?(d|t)(!)?|provide|path|quickstart|replace|sample|(my)?secret|self|spec\.|str:|(my)?t(e)?mp|test|this|update|value|your_)(.+?)?[\"\']''',
      ## Ends with
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'][^\'\"]*?(\.((jp(e)?g)|png|svg|txt|tmpl)|-auth(entication)?|-cert(ification)?(s)?|-demo|-encryption|(-|_)key|-tls|_id|_private|(0)?12345(6)?|client|(change|fix)me|conf(ig(uration)?)?|cred(ential)?(s)?|data|default|devel(opment)|example(.com|key)?|hash|here|json|(_|-)pwd|placeholder|pass((w)?(o|0)?(r)?(d|t)(\d*?)(!)?)?|principal|raw\(|registry|required|secret(s|_v\d)?(key)?|string|test|token|uuid|value|xxxxx|y(a)?ml)(&gt;|\\u003e)?[\"\']''',
      ## Contains
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'][^\'\"]*?(client(-)?secret|example)[^\'\"]*?[\"\']''',
      # Ignore things that look like UUIDs (So far these have more often referenced secrets rather than being them)
      '''(?i)(token)(_|-)?(key)?[\"\']?(\s+)?[:=](\s+)?[\"\'](?-i)[0-9a-z]{8}-[0-9a-z]{4}-[0-9a-z]{4}-[0-9a-z]{4}-[0-9a-z]{12}[\"\']''',
    ]

[[rules]]
  # This handles UNQUOTED values in YAML files (the other rules should be able
  # to handle quoted values).
  # Once this is production ready take off the "(YAML) bit so it gets sent with
  # other general secret matches.
  description="(YAML) General Secret"
  path='''\.y(a)?ml$'''
  regex = '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*([^\"\'\s]+?)\s*(#|$)'''
  tags = ["group:leaktk-testing", "yaml", "key", "secret", "general", "type:secret"]

  [[rules.entropies]]
    Min = "3.35"
    Max = "8"
    Group = "6"

  [rules.allowlist]
    paths = [
      # Test data files are often false positives
      '''(^|\/)testdata\/''',
    ]
    regexes = [
      # Things like:
      #   - secret: <PLACEHOLDER>
      #   - secret: @@PLACEHOLDER@@
      #   - secret: %PLACEHOLDER%
      #   - secret: $PLACEHOLDER$
      #   - secret: __PLACEHOLDER__
      #   - secret: _PLACEHOLDER_
      #   - secret: ALL_UPPER_LETTERS_OR_UNDERSCORS
      #   - secret: {PLACEHOLDER}
      #   - secret: ${PLACEHOLDER}
      #   - secret: %{PLACEHOLDER}
      #   - secret: update-your-postgres-pass-here # a common placeholder setup
      #   - secret: Some...placeholder
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*(@@.+?@@|<.+?>|%.+?%|\$.+?\$|_.+?_|(?-i)[A-Z_]+?|(\$|%)?\{.+?\}|(?-i).+?[a-z]{2,}-[a-z]{2,}-[a-z]{2,}.+?|.*\.\.\..*)''',
      #   - secret: [%PLACEHOLDER%]"
      #   - secret: [PLACEHOLDER]
      #   - secret: $(PLACEHOLDER...
      #   - secret: \$(PLACEHOLDER...
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*(\[%.+%\]|\[.+?\]|(\\)?\$\(.*)''',
      #   - secret: SOME_CONSTANT_PREFIX_${PLACEHOLDER}
      #   - secret: /SOME/path:${PLACEHOLDER}...
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*[a-z\-\_\/\:]{4,}\$\{[a-z\_\.\$\{\}]{4,}?\}''',
      #   - secret: $SOME_ENV_VARIABLE-optional-text
      #   - secret: \$SOME_ENV_VARIABLE-optional-text
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*(?-i)(\\)?\$[A-Z][0-9A-Z_]{4,}([\w\-]+)?''',
      # Ignore EXAMPLE base64 encoded
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*.*?(RVhBTVBMR|VYQU1QTEU|FWEFNUExF).*?''',
      # Various words at the start and end that signify a placeholder
      # THESE WILL NEED TO BE UPDATED AFTER MOVING OVER TO MATCH THE OTHER LISTS
      ## Starts with
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*(&lt;|\\u201c|\$)?(\/etc\/|data\/|\/path\/|(\/var)?\/run\/|(0)?12345|abc(d|12)|admin|ansible|auto|bool:|capi-openstack|change|client|confirm|contrase|demo|dict|django-insecure-|example|(ENC\[|RU5DW|VOQ|FTk)|enter_|fake|false|file:|fixme|grub|http(s)?:\/\/|installation_prefix|invalid|libvirt|none|not|placeholder|pass(w)?(o|0)?(r)?(d|t)(!)?|provide|path|quickstart|replace|sample|(my)?secret|self|ssh|spec\.|str:|(my)?t(e)?mp|test|this|update|value|your_).*''',
      ## Ends with
      '''(?i)(secret|password|token)(_|-)?(access)?(_|-)?(key)?[\"\']?\s*:\s*.*(\.((jp(e)?g)|png|svg|txt|tmpl)|-auth(entication)?|-cert(ification)?(s)?|-demo|-encryption|(-|_)key|-tls|_id|_private|(0)?12345(6)?|client|(change|fix)me|conf(ig(uration)?)?|cred(ential)?(s)?|data|default|devel(opment)|example(.com|key)?|hash|here|json|(_|-)pwd|placeholder|pass((w)?(o|0)?(r)?(d|t)(\d*?)(!)?)?|principal|raw\(|registry|required|secret(s|_v\d)?|string|test|token|uuid|value|y(a)?ml)[\"\']?''',
    ]

[[rules]]
  description = "OpenShift Login Token"
  regex='''\boc\s+login\s+.*?--token\s*(=)?\s*(sha256~[^\s]+)\b'''
  tags = ["group:leaktk-testing", "openshift-login", "token", "type:secret"]

[[rules.entropies]]
  # This may or may not be needed. Review the testing results to see if the
  # results are high fidelity enough to see if this needs to be allowlist based
  # or entropy based
  Min = "0"
  Max = "8"
  Group = "2"

[[rules]]
  # Might merge this with AWS Secret Key if the quality is good
  # (other rule|this new rule)
  description = "Potential AWS Secret Key"
  regex = '''(?i)[^a-z0-9\/+=\.\-<>_;]([a-z0-9\/+=]{40})([^a-z0-9\/+=\.\-<>_]|$)'''
  # Update alert tags and remove "testing" tag when ready
  # May set this up to never alert users directly but instead feed it
  # to a cred checker tool if we can't get a higher number of true positives.
  tags = ["group:leaktk-testing", "key", "aws", "type:secret"]

  [[rules.entropies]]
    # 4.4 also cuts out out a lot of FPs but might cut out some TPs as well
    # keep an eye on this range.
    Min = "4.2"
    Max = "8"
    Group = "1"

  [rules.allowlist]
    regexes = [
      # kind of a sanity check to cut down fps in the initial round of testing
      '''(?i)[^a-z0-9\/+=\.\-<>_;]([a-z]{40}|[a-z]{0,39}\d[a-z]{0,39})([^a-z0-9\/+=\.\-<>_]|$)''',
      # It must have at least 1 upper and lower case character
      '''[^A-Za-z0-9\/+=\.\-<>_;]([a-z0-9\/+=]{40}|[A-Z0-9\/+=]{40})([^a-z0-9\/+=\.\-<>_]|$)''',
      # Things then end in = often seem to be just base64 encoded values or keys not related to AWS
      '''[^A-Za-z0-9\/+=\.\-<>_;][A-Za-z0-9\/+=]{39}=([^A-Za-z0-9\/+=\.\-<>_]|$)''',
      # Ignore things with 3 or more slashes in it. So far most keys don't have this.
      # (This rule might be able to replace a lot of the other ones here, need to
      # go back and run this against older matches)
      '''(?i)[^a-z0-9\/+=\.\-<>_;](.+\/.+){3}([^a-z0-9\/+=\.\-<>_]|$)''',
      # Ignore placeholders
      # Note: this runs the risk of missing real keys if everything is one line and there's a match elsewhere
      # but it cuts out so many FPs it may be worth it.
      '''(?i)[^a-z0-9\/+=\.\-<>_;][a-z0-9\/+=]{0,40}(1234|abc(d|12)|algo|api|attr|auth|base|body|com|dist|example|exec|hook|ident|java|linux|name|org|param|path|repo|resp|share|spec|temp|test|type|xxx)[a-z0-9\/+=]{0,40}([^a-z0-9\/+=\.\-<>_]|$)'''
    ]

# Not ready to deploy yet, need to set entropy flags and make sure the keys are
# right and add tests
# Make sure to add entropy checks too and ignore FPs
[[rules]]
description = "Kubernetes Docker Config"
regex='''\.dockerconfigjson.*(ImF1dGhzI|JhdXRocyI|iYXV0aHMi)[a-zA-Z0-9+/=]+'''
tags = ["group:leaktk-testing", "key", "container-registry", "type:secret"]
# This one needs testing too and the allowlist tuning
[[rules]]
description = "Container Pull Secret Fragment"
regex='''(ImF1dGhzI|JhdXRocyI|iYXV0aHMi).+?(ImF1dGgiO|JhdXRoIjo|iYXV0aCI6)'''
tags = ["group:leaktk-testing", "key", "container-registry", "type:secret"]
